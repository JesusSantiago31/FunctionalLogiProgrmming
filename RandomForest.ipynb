{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee900780",
   "metadata": {},
   "source": [
    "# Caso Pr√°ctico: Random Forest\n",
    "\n",
    "En este caso de uso pr√°ctico se pretende resolver un problema de detecci√≥n de malware en dispositivos Android, mediante el analisis de tr√°fico de red qie genera el dispositivo mediante el uso de Conjuntos de √°rboles de desici√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e397033",
   "metadata": {},
   "source": [
    "# Caso Pr√°ctico: Random Forest\n",
    "\n",
    "En este caso de uso pr√°ctico se pretende resolver un problema de detecci√≥n de malware en dispositivos Android, mediante el analisis de tr√°fico de red qie genera el dispositivo mediante el uso de Conjuntos de √°rboles de desici√≥n\n",
    "\n",
    "### DataSet: Detecci√≥n de Malware en Android\n",
    "\n",
    "#### Description\n",
    "The sophisticated and advanced Android malware is able to identify the presence of the emulator used by the malware analyst and in response, alter its behavior to evade detection. To overcome this issue, we installed the Android applications on the real device and captured its network traffic. See our publicly available Android Sandbox.\n",
    "\n",
    "CICAAGM dataset is captured by installing the Android apps on the real smartphones semi-automated. The dataset is generated from 1900 applications with the following three categories:\n",
    "\n",
    "**1. Adware (250 apps)**\n",
    "* Airpush: Designed to deliver unsolicited advertisements to the user‚Äôs systems for information stealing.\n",
    "* Dowgin: Designed as an advertisement library that can also steal the user‚Äôs information.\n",
    "* Kemoge: Designed to take over a user‚Äôs Android device. This adware is a hybrid of botnet and disguises itself as popular apps via repackaging.\n",
    "* Mobidash: Designed to display ads and to compromise user‚Äôs personal information.\n",
    "* Shuanet: Similar to Kemoge, Shuanet also is designed to take over a user‚Äôs device.\n",
    "\n",
    "**2. General Malware (150 apps)**\n",
    "* AVpass: Designed to be distributed in the guise of a Clock app.\n",
    "* FakeAV: Designed as a scam that tricks user to purchase a full version of the software in order to re-mediate non-existing infections.\n",
    "* FakeFlash/FakePlayer: Designed as a fake Flash app in order to direct users to a website (after successfully installed).\n",
    "* GGtracker: Designed for SMS fraud (sends SMS messages to a premium-rate number) and information stealing.\n",
    "* Penetho: Designed as a fake service (hacktool for Android devices that can be used to crack the WiFi password). The malware is also able to infect the user‚Äôs computer via infected email attachment, fake updates, external media and infected documents.\n",
    "\n",
    "**3. Benign (1500 apps)**\n",
    "* 2015 GooglePlay market (top free popular and top free new)\n",
    "* 2016 GooglePlay market (top free popular and top free new)\n",
    "\n",
    "### Ficheros de datos\n",
    "* pcap files ‚Äì the network traffic of both the malware and benign (20% malware and 80% benign)\n",
    "* <span style=\"color:green\">.csv files - the list of extracted network traffic features generated by the CIC-flowmeter</span>\n",
    "\n",
    "### Descarga de los ficheros de datos\n",
    "https://www.unb.ca/cic/datasets/android-adware.html\n",
    "\n",
    "### Referencias adicionales sobre el conjunto de datos\n",
    "_Arash Habibi Lashkari, Andi Fitriah A. Kadir, Hugo Gonzalez, Kenneth Fon Mbah and Ali A. Ghorbani, ‚ÄúTowards a Network-Based Framework for Android Malware Detection and Characterization‚Äù, In the proceeding of the 15th International Conference on Privacy, Security and Trust, PST, Calgary, Canada, 2017._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e70959",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00188067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb80b5d",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac03329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcci√≥n de una funci√≥n que realice el particionado completo\n",
    "def train_val_test_split(df, rstate=42, shuffle=True, stratify=None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "        df, test_size=0.4, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(\n",
    "        test_set, test_size=0.5, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    return (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94474aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_labels(df, label_name):\n",
    "    X = df.drop(label_name, axis=1)\n",
    "    y = df[label_name].copy()\n",
    "    return (X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dee9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_result(y_pred, y, y_prep_pred, y_prep, metric):\n",
    "    print(metric.__name__, \"WITHOUT preparation:\", metric(y_pred, y, average='weighted'))\n",
    "\n",
    "    print(metric.__name__, \"WITH preparation:\", metric(y_prep_pred, y_prep, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62826b76",
   "metadata": {},
   "source": [
    "### 1.- Lectura del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340290ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/datasets/TotalFeatures-ISCXFlowMeter.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b2dcc",
   "metadata": {},
   "source": [
    "### 2.- Visualizaci√≥n del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d06fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d62ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a59511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8dda42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver la longitud de los datos\n",
    "print(\"Longitud del DataSet\", len(df))\n",
    "print(\"N√∫mero de caracteristicas del DataSet\", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f253e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['calss'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a76fb2",
   "metadata": {},
   "source": [
    "##### Convertir una salida categorica a una categorica numerica\n",
    "## Buscando Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f19225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar la variable de salida num√©rica para buscar correlaciones\n",
    "X = df.copy()\n",
    "# Pasar de variable categorica a numerica [0] -> Toma un array en una sola dimension\n",
    "X['calss'] = X['calss'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular las correlaciones\n",
    "corr_matrix  = X.corr()\n",
    "corr_matrix['calss'].sort_values(ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede llegar a valorar quedarse con aquellas que tienen mayor correlaci√≥n \n",
    "corr_matrix[corr_matrix['calss'] > 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4731ce",
   "metadata": {},
   "source": [
    "## 3.- Divisi√≥n del DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1908d626",
   "metadata": {},
   "source": [
    "# Dvividir el dataset\n",
    "train_set, val_set, test_set = train_val_test_split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f386bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separas esa etiqueta calss, solo vamos a usar calss para reducir la carga de trabajo al hardware\n",
    "X_train, y_train = remove_labels(train_set, 'calss')\n",
    "X_val, y_val = remove_labels(val_set, 'calss')\n",
    "X_test, y_test = remove_labels(test_set, 'calss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8bb491",
   "metadata": {},
   "source": [
    "# 4.-Escalando el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8bec5d",
   "metadata": {},
   "source": [
    "Es importnte comprender que lo √°rbole de desici√≥n son algoritmos que **no requieren demasiada preparaci√≥n de los datos** correctamente, no requieren la realizaci√≥n o escalado o normalizaci√≥. En este ejercicio se ve a realizar escalado al Dataset y se van a comparar los resultados con el DataSet sin escala. De esta manera, se demuestra como aplicar preprocesamientos como el escaladopuedr llrgsr s sfectar el rendimiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_val_scaled = scaler.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d4554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar un DataFrame de pandas\n",
    "from pandas import DataFrame\n",
    "X_train_scaled = DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_train_scaled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e79271",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ea11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fe4adb",
   "metadata": {},
   "source": [
    "## 5.- Decision Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo entrenado con el DataSet sin escalar\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(random_state=42)\n",
    "clf_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos el DataSet de Entrenamiento\n",
    "y_train_pred = clf_tree.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da216b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 Score Train Set: \", f1_score(y_train_pred, y_train, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28efb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir con el DataSet de validadci√≥n \n",
    "y_val_pred = clf_tree.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de573073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar los resultados entre escalado y sin escalar\n",
    "print(\"F1 Score Validation Set: \", f1_score(y_val_pred, y_val, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb9dea",
   "metadata": {},
   "source": [
    "# 1.- Modelo de entrenamiento escalado y sin escalar\n",
    "# 2.- Comparaci√≥n de ambos modelos\n",
    "# La prediccion de datos de validaci√≥n\n",
    "# 4.- COmparar los resultados con escalar y sin escalar\n",
    "# 7.- Regresion Forest\n",
    "Los √°rboles y conjuntos de √°rboles de decision tambi√©n pueden aplicarse a problemas de regresi√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bea896",
   "metadata": {},
   "source": [
    "## 1.- Modelo de entrenamiento escalado y sin escalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e39988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- Escalado del dataset\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def scale_datasets(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "    Escala los conjuntos de entrenamiento, validaci√≥n y prueba usando RobustScaler.\n",
    "    Retorna las versiones escaladas en el mismo orden.\n",
    "    \"\"\"\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    X_val_scaled = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled\n",
    "\n",
    "X_train_scaled, X_val_scaled, X_test_scaled = scale_datasets(X_train, X_val, X_test)\n",
    "print(\"Escalado completado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- Random Forest sin escalar\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def train_rf_unscaled(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Entrena un RandomForestClassifier sin escalar los datos.\n",
    "    \"\"\"\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "clf_rf_unscaled = train_rf_unscaled(X_train, y_train)\n",
    "\n",
    "y_train_pred_unscaled = clf_rf_unscaled.predict(X_train)\n",
    "y_val_pred_unscaled = clf_rf_unscaled.predict(X_val)\n",
    "y_test_pred_unscaled = clf_rf_unscaled.predict(X_test)\n",
    "\n",
    "print(\"=== Random Forest (SIN escalar) ===\")\n",
    "print(\"F1 Train:\", f1_score(y_train, y_train_pred_unscaled, average='weighted'))\n",
    "print(\"F1 Val:  \", f1_score(y_val, y_val_pred_unscaled, average='weighted'))\n",
    "print(\"F1 Test: \", f1_score(y_test, y_test_pred_unscaled, average='weighted'))\n",
    "print(\"\\nReporte de clasificaci√≥n (Validaci√≥n):\")\n",
    "print(classification_report(y_val, y_val_pred_unscaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.- Modelo de entrenamiento CON escalar\n",
    "clf_rf_scaled = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "clf_rf_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_train_pred_scaled = clf_rf_scaled.predict(X_train_scaled)\n",
    "y_val_pred_scaled = clf_rf_scaled.predict(X_val_scaled)\n",
    "y_test_pred_scaled = clf_rf_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Evaluacion\n",
    "print(\"Random Forest (ESCALADO) \")\n",
    "print(\"Train F1-weighted:\", f1_score(y_train, y_train_pred_scaled, average='weighted'))\n",
    "print(\"Val   F1-weighted:\", f1_score(y_val, y_val_pred_scaled, average='weighted'))\n",
    "print(\"Test  F1-weighted:\", f1_score(y_test, y_test_pred_scaled, average='weighted'))\n",
    "print(\"\\nClassification report (Validation):\\n\", classification_report(y_val, y_val_pred_scaled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba78359",
   "metadata": {},
   "source": [
    "# 2.- Comparaci√≥n de ambos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94863879",
   "metadata": {},
   "source": [
    "evaluate_result(\n",
    "    y_val_pred_unscaled, y_val,\n",
    "    y_val_pred_scaled, y_val,\n",
    "    f1_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c81a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.- Comparaci√≥n de ambos modelos \n",
    "\n",
    "f1_train_unscaled = f1_score(y_train, y_train_pred_unscaled, average='weighted')\n",
    "f1_val_unscaled   = f1_score(y_val, y_val_pred_unscaled, average='weighted')\n",
    "f1_test_unscaled  = f1_score(y_test, y_test_pred_unscaled, average='weighted')\n",
    "\n",
    "f1_train_scaled = f1_score(y_train, y_train_pred_scaled, average='weighted')\n",
    "f1_val_scaled   = f1_score(y_val, y_val_pred_scaled, average='weighted')\n",
    "f1_test_scaled  = f1_score(y_test, y_test_pred_scaled, average='weighted')\n",
    "\n",
    "print(\"COMPARACI√ìN DE MODELOS\")\n",
    "print(f\"Train (Sin escalar): {f1_train_unscaled:.4f} | (Escalado): {f1_train_scaled:.4f}\")\n",
    "print(f\"Valid (Sin escalar): {f1_val_unscaled:.4f} | (Escalado): {f1_val_scaled:.4f}\")\n",
    "print(f\"Test  (Sin escalar): {f1_test_unscaled:.4f} | (Escalado): {f1_test_scaled:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51388f34",
   "metadata": {},
   "source": [
    "## 7.- Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.- Random Forest Regressor ‚Äî ejemplo\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Selecciona la primera columna num√©rica para el ejemplo de regresi√≥n\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c != 'calss']  # evitar la etiqueta\n",
    "\n",
    "if len(numeric_cols) == 0:\n",
    "    print(\"‚ùå No se encontraron columnas num√©ricas para regresi√≥n.\")\n",
    "else:\n",
    "    target_col = numeric_cols[0]\n",
    "    print(f\"üéØ Usando columna '{target_col}' como variable objetivo para regresi√≥n.\")\n",
    "\n",
    "    # Construir datasets de regresi√≥n\n",
    "    X_reg_train = X_train.drop(columns=[target_col])\n",
    "    X_reg_val = X_val.drop(columns=[target_col])\n",
    "    X_reg_test = X_test.drop(columns=[target_col])\n",
    "\n",
    "    y_reg_train = X_train[target_col]\n",
    "    y_reg_val = X_val[target_col]\n",
    "    y_reg_test = X_test[target_col]\n",
    "\n",
    "    # Escalar features\n",
    "    scaler_reg = RobustScaler()\n",
    "    X_reg_train_scaled = pd.DataFrame(scaler_reg.fit_transform(X_reg_train), columns=X_reg_train.columns, index=X_reg_train.index)\n",
    "    X_reg_val_scaled = pd.DataFrame(scaler_reg.transform(X_reg_val), columns=X_reg_val.columns, index=X_reg_val.index)\n",
    "    X_reg_test_scaled = pd.DataFrame(scaler_reg.transform(X_reg_test), columns=X_reg_test.columns, index=X_reg_test.index)\n",
    "\n",
    "    # Entrenar Regressor\n",
    "    rfr = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rfr.fit(X_reg_train_scaled, y_reg_train)\n",
    "\n",
    "    # Predicciones\n",
    "    y_reg_pred = rfr.predict(X_reg_val_scaled)\n",
    "\n",
    "    # M√©tricas\n",
    "    print(\"MAE (val):\", mean_absolute_error(y_reg_val, y_reg_pred))\n",
    "    print(\"MSE (val):\", mean_squared_error(y_reg_val, y_reg_pred))\n",
    "    print(\"R¬≤ (val):\", r2_score(y_reg_val, y_reg_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
