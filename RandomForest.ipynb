{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee900780",
   "metadata": {},
   "source": [
    "# Caso Práctico: Random Forest\n",
    "\n",
    "En este caso de uso práctico se pretende resolver un problema de detección de malware en dispositivos Android, mediante el analisis de tráfico de red qie genera el dispositivo mediante el uso de Conjuntos de árboles de desición"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e397033",
   "metadata": {},
   "source": [
    "# Caso Práctico: Random Forest\n",
    "\n",
    "En este caso de uso práctico se pretende resolver un problema de detección de malware en dispositivos Android, mediante el analisis de tráfico de red qie genera el dispositivo mediante el uso de Conjuntos de árboles de desición\n",
    "\n",
    "### DataSet: Detección de Malware en Android\n",
    "\n",
    "#### Description\n",
    "The sophisticated and advanced Android malware is able to identify the presence of the emulator used by the malware analyst and in response, alter its behavior to evade detection. To overcome this issue, we installed the Android applications on the real device and captured its network traffic. See our publicly available Android Sandbox.\n",
    "\n",
    "CICAAGM dataset is captured by installing the Android apps on the real smartphones semi-automated. The dataset is generated from 1900 applications with the following three categories:\n",
    "\n",
    "**1. Adware (250 apps)**\n",
    "* Airpush: Designed to deliver unsolicited advertisements to the user’s systems for information stealing.\n",
    "* Dowgin: Designed as an advertisement library that can also steal the user’s information.\n",
    "* Kemoge: Designed to take over a user’s Android device. This adware is a hybrid of botnet and disguises itself as popular apps via repackaging.\n",
    "* Mobidash: Designed to display ads and to compromise user’s personal information.\n",
    "* Shuanet: Similar to Kemoge, Shuanet also is designed to take over a user’s device.\n",
    "\n",
    "**2. General Malware (150 apps)**\n",
    "* AVpass: Designed to be distributed in the guise of a Clock app.\n",
    "* FakeAV: Designed as a scam that tricks user to purchase a full version of the software in order to re-mediate non-existing infections.\n",
    "* FakeFlash/FakePlayer: Designed as a fake Flash app in order to direct users to a website (after successfully installed).\n",
    "* GGtracker: Designed for SMS fraud (sends SMS messages to a premium-rate number) and information stealing.\n",
    "* Penetho: Designed as a fake service (hacktool for Android devices that can be used to crack the WiFi password). The malware is also able to infect the user’s computer via infected email attachment, fake updates, external media and infected documents.\n",
    "\n",
    "**3. Benign (1500 apps)**\n",
    "* 2015 GooglePlay market (top free popular and top free new)\n",
    "* 2016 GooglePlay market (top free popular and top free new)\n",
    "\n",
    "### Ficheros de datos\n",
    "* pcap files – the network traffic of both the malware and benign (20% malware and 80% benign)\n",
    "* <span style=\"color:green\">.csv files - the list of extracted network traffic features generated by the CIC-flowmeter</span>\n",
    "\n",
    "### Descarga de los ficheros de datos\n",
    "https://www.unb.ca/cic/datasets/android-adware.html\n",
    "\n",
    "### Referencias adicionales sobre el conjunto de datos\n",
    "_Arash Habibi Lashkari, Andi Fitriah A. Kadir, Hugo Gonzalez, Kenneth Fon Mbah and Ali A. Ghorbani, “Towards a Network-Based Framework for Android Malware Detection and Characterization”, In the proceeding of the 15th International Conference on Privacy, Security and Trust, PST, Calgary, Canada, 2017._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e70959",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00188067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb80b5d",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac03329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción de una función que realice el particionado completo\n",
    "def train_val_test_split(df, rstate=42, shuffle=True, stratify=None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "        df, test_size=0.4, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(\n",
    "        test_set, test_size=0.5, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    return (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94474aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_labels(df, label_name):\n",
    "    X = df.drop(label_name, axis=1)\n",
    "    y = df[label_name].copy()\n",
    "    return (X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dee9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_result(y_pred, y, y_prep_pred, y_prep, metric):\n",
    "    print(metric.__name__, \"WITHOUT preparation:\", metric(y_pred, y, average='weighted'))\n",
    "\n",
    "    print(metric.__name__, \"WITH preparation:\", metric(y_prep_pred, y_prep, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62826b76",
   "metadata": {},
   "source": [
    "### 1.- Lectura del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340290ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/datasets/TotalFeatures-ISCXFlowMeter.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b2dcc",
   "metadata": {},
   "source": [
    "### 2.- Visualización del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d06fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d62ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a59511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8dda42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver la longitud de los datos\n",
    "print(\"Longitud del DataSet\", len(df))\n",
    "print(\"Número de caracteristicas del DataSet\", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f253e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['calss'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a76fb2",
   "metadata": {},
   "source": [
    "##### Convertir una salida categorica a una categorica numerica\n",
    "## Buscando Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f19225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar la variable de salida numérica para buscar correlaciones\n",
    "X = df.copy()\n",
    "# Pasar de variable categorica a numerica [0] -> Toma un array en una sola dimension\n",
    "X['calss'] = X['calss'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular las correlaciones\n",
    "corr_matrix  = X.corr()\n",
    "corr_matrix['calss'].sort_values(ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede llegar a valorar quedarse con aquellas que tienen mayor correlación \n",
    "corr_matrix[corr_matrix['calss'] > 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4731ce",
   "metadata": {},
   "source": [
    "## 3.- División del DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1908d626",
   "metadata": {},
   "source": [
    "# Dvividir el dataset\n",
    "train_set, val_set, test_set = train_val_test_split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f386bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separas esa etiqueta calss, solo vamos a usar calss para reducir la carga de trabajo al hardware\n",
    "X_train, y_train = remove_labels(train_set, 'calss')\n",
    "X_val, y_val = remove_labels(val_set, 'calss')\n",
    "X_test, y_test = remove_labels(test_set, 'calss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8bb491",
   "metadata": {},
   "source": [
    "# 4.-Escalando el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8bec5d",
   "metadata": {},
   "source": [
    "Es importnte comprender que lo árbole de desición son algoritmos que **no requieren demasiada preparación de los datos** correctamente, no requieren la realización o escalado o normalizació. En este ejercicio se ve a realizar escalado al Dataset y se van a comparar los resultados con el DataSet sin escala. De esta manera, se demuestra como aplicar preprocesamientos como el escaladopuedr llrgsr s sfectar el rendimiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_val_scaled = scaler.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d4554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar un DataFrame de pandas\n",
    "from pandas import DataFrame\n",
    "X_train_scaled = DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_train_scaled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e79271",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ea11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fe4adb",
   "metadata": {},
   "source": [
    "## 5.- Decision Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo entrenado con el DataSet sin escalar\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(random_state=42)\n",
    "clf_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos el DataSet de Entrenamiento\n",
    "y_train_pred = clf_tree.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da216b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 Score Train Set: \", f1_score(y_train_pred, y_train, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28efb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir con el DataSet de validadción \n",
    "y_val_pred = clf_tree.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de573073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar los resultados entre escalado y sin escalar\n",
    "print(\"F1 Score Validation Set: \", f1_score(y_val_pred, y_val, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb9dea",
   "metadata": {},
   "source": [
    "# 1.- Modelo de entrenamiento escalado y sin escalar\n",
    "# 2.- Comparación de ambos modelos\n",
    "# La prediccion de datos de validación\n",
    "# 4.- COmparar los resultados con escalar y sin escalar\n",
    "# 7.- Regresion Forest\n",
    "Los árboles y conjuntos de árboles de decision también pueden aplicarse a problemas de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bea896",
   "metadata": {},
   "source": [
    "## 1.- Modelo de entrenamiento escalado y sin escalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e39988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- Escalado del dataset\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def scale_datasets(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "    Escala los conjuntos de entrenamiento, validación y prueba usando RobustScaler.\n",
    "    Retorna las versiones escaladas en el mismo orden.\n",
    "    \"\"\"\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    X_val_scaled = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled\n",
    "\n",
    "X_train_scaled, X_val_scaled, X_test_scaled = scale_datasets(X_train, X_val, X_test)\n",
    "print(\"Escalado completado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- Random Forest sin escalar\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def train_rf_unscaled(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Entrena un RandomForestClassifier sin escalar los datos.\n",
    "    \"\"\"\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "clf_rf_unscaled = train_rf_unscaled(X_train, y_train)\n",
    "\n",
    "y_train_pred_unscaled = clf_rf_unscaled.predict(X_train)\n",
    "y_val_pred_unscaled = clf_rf_unscaled.predict(X_val)\n",
    "y_test_pred_unscaled = clf_rf_unscaled.predict(X_test)\n",
    "\n",
    "print(\"=== Random Forest (SIN escalar) ===\")\n",
    "print(\"F1 Train:\", f1_score(y_train, y_train_pred_unscaled, average='weighted'))\n",
    "print(\"F1 Val:  \", f1_score(y_val, y_val_pred_unscaled, average='weighted'))\n",
    "print(\"F1 Test: \", f1_score(y_test, y_test_pred_unscaled, average='weighted'))\n",
    "print(\"\\nReporte de clasificación (Validación):\")\n",
    "print(classification_report(y_val, y_val_pred_unscaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.- Modelo de entrenamiento CON escalar\n",
    "clf_rf_scaled = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "clf_rf_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_train_pred_scaled = clf_rf_scaled.predict(X_train_scaled)\n",
    "y_val_pred_scaled = clf_rf_scaled.predict(X_val_scaled)\n",
    "y_test_pred_scaled = clf_rf_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Evaluacion\n",
    "print(\"Random Forest (ESCALADO) \")\n",
    "print(\"Train F1-weighted:\", f1_score(y_train, y_train_pred_scaled, average='weighted'))\n",
    "print(\"Val   F1-weighted:\", f1_score(y_val, y_val_pred_scaled, average='weighted'))\n",
    "print(\"Test  F1-weighted:\", f1_score(y_test, y_test_pred_scaled, average='weighted'))\n",
    "print(\"\\nClassification report (Validation):\\n\", classification_report(y_val, y_val_pred_scaled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba78359",
   "metadata": {},
   "source": [
    "# 2.- Comparación de ambos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94863879",
   "metadata": {},
   "source": [
    "evaluate_result(\n",
    "    y_val_pred_unscaled, y_val,\n",
    "    y_val_pred_scaled, y_val,\n",
    "    f1_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c81a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.- Comparación de ambos modelos \n",
    "\n",
    "f1_train_unscaled = f1_score(y_train, y_train_pred_unscaled, average='weighted')\n",
    "f1_val_unscaled   = f1_score(y_val, y_val_pred_unscaled, average='weighted')\n",
    "f1_test_unscaled  = f1_score(y_test, y_test_pred_unscaled, average='weighted')\n",
    "\n",
    "f1_train_scaled = f1_score(y_train, y_train_pred_scaled, average='weighted')\n",
    "f1_val_scaled   = f1_score(y_val, y_val_pred_scaled, average='weighted')\n",
    "f1_test_scaled  = f1_score(y_test, y_test_pred_scaled, average='weighted')\n",
    "\n",
    "print(\"COMPARACIÓN DE MODELOS\")\n",
    "print(f\"Train (Sin escalar): {f1_train_unscaled:.4f} | (Escalado): {f1_train_scaled:.4f}\")\n",
    "print(f\"Valid (Sin escalar): {f1_val_unscaled:.4f} | (Escalado): {f1_val_scaled:.4f}\")\n",
    "print(f\"Test  (Sin escalar): {f1_test_unscaled:.4f} | (Escalado): {f1_test_scaled:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51388f34",
   "metadata": {},
   "source": [
    "## 7.- Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.- Random Forest Regressor — ejemplo\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Selecciona la primera columna numérica para el ejemplo de regresión\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c != 'calss']  # evitar la etiqueta\n",
    "\n",
    "if len(numeric_cols) == 0:\n",
    "    print(\"❌ No se encontraron columnas numéricas para regresión.\")\n",
    "else:\n",
    "    target_col = numeric_cols[0]\n",
    "    print(f\"🎯 Usando columna '{target_col}' como variable objetivo para regresión.\")\n",
    "\n",
    "    # Construir datasets de regresión\n",
    "    X_reg_train = X_train.drop(columns=[target_col])\n",
    "    X_reg_val = X_val.drop(columns=[target_col])\n",
    "    X_reg_test = X_test.drop(columns=[target_col])\n",
    "\n",
    "    y_reg_train = X_train[target_col]\n",
    "    y_reg_val = X_val[target_col]\n",
    "    y_reg_test = X_test[target_col]\n",
    "\n",
    "    # Escalar features\n",
    "    scaler_reg = RobustScaler()\n",
    "    X_reg_train_scaled = pd.DataFrame(scaler_reg.fit_transform(X_reg_train), columns=X_reg_train.columns, index=X_reg_train.index)\n",
    "    X_reg_val_scaled = pd.DataFrame(scaler_reg.transform(X_reg_val), columns=X_reg_val.columns, index=X_reg_val.index)\n",
    "    X_reg_test_scaled = pd.DataFrame(scaler_reg.transform(X_reg_test), columns=X_reg_test.columns, index=X_reg_test.index)\n",
    "\n",
    "    # Entrenar Regressor\n",
    "    rfr = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rfr.fit(X_reg_train_scaled, y_reg_train)\n",
    "\n",
    "    # Predicciones\n",
    "    y_reg_pred = rfr.predict(X_reg_val_scaled)\n",
    "\n",
    "    # Métricas\n",
    "    print(\"MAE (val):\", mean_absolute_error(y_reg_val, y_reg_pred))\n",
    "    print(\"MSE (val):\", mean_squared_error(y_reg_val, y_reg_pred))\n",
    "    print(\"R² (val):\", r2_score(y_reg_val, y_reg_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
